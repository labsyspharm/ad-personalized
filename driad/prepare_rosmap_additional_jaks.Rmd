---
title: "DRIAD additional JAKs"
author: "Clemens Hug"
output: html_document
---


```{r setup}
library(tidyverse)
library(synExtra)
library(data.table)
library(powerjoin)
library(here)
library(qs)

synapser::synLogin()
syn <- synDownloader("~/data", .cache = TRUE)

data_dir <- file.path("driad", "additional_jaks")
dir.create(data_dir, showWarnings = FALSE)
```



syn51671579 - From 1-20230210-ReN-ovca-mel-test
syn51722827 - From 2-20230412-ReN-AD-repurposing-Albers
  -> Don't use, failed run. Almost no signal in any drug
syn55688087 - From 3-20240206-ReN-AD-repurposing-Albers
syn63854253 - From 4-20240823-ReN-chromatin-modifiers-Albers

```{r}
drugs_of_interest <- c(
  "baricitinib",
  "ruxolitinib"
)

all_res_raw <- list(
  `1-20230210-ReN-ovca-mel-test` = syn("syn51671579") %>%
    read_csv() %>%
    transmute(
      drug = str_to_lower(agent),
      ensembl_gene_id, hgnc_symbol,
      log2FoldChange, pvalue, padj
    ) %>%
    filter(drug %in% drugs_of_interest),
  `3-20240206-ReN-AD-repurposing-Albers` = syn("syn55688087") %>%
    read_csv() %>%
    transmute(
      drug,
      ensembl_gene_id, hgnc_symbol,
      pvalue, padj
    ) %>%
    filter(drug %in% drugs_of_interest),
  `4-20240823-ReN-chromatin-modifiers-Albers` = syn("syn63854253") %>%
    read_csv() %>%
    transmute(
      drug = str_to_lower(agent),
      ensembl_gene_id, hgnc_symbol,
      pvalue, padj
    ) %>%
    filter(drug %in% drugs_of_interest)
) %>%
  bind_rows(.id = "experiment")

all_res_gene_sets <- all_res_raw %>%
  filter(padj < 0.05) %>%
  arrange(pvalue) %>%
  group_by(
    experiment, drug
  ) %>%
  filter(
    cumsum(!duplicated(ensembl_gene_id)) <= 300
  ) %>%
  nest() %>%
  mutate(
    gs_id = paste0(experiment, "_", drug)
  ) %>%
  ungroup()

qsave(
  all_res_gene_sets,
  file.path(data_dir, "all_res_gene_sets.qs")
)

all_res_gene_sets %>% mutate(n = map_int(data, nrow))
```

```
# A tibble: 6 Ã— 3
  experiment                                drug            n
  <chr>                                     <chr>       <int>
1 1-20230210-ReN-ovca-mel-test              baricitinib    21
2 1-20230210-ReN-ovca-mel-test              ruxolitinib    17
3 3-20240206-ReN-AD-repurposing-Albers      baricitinib    76
4 3-20240206-ReN-AD-repurposing-Albers      ruxolitinib   112
5 4-20240823-ReN-chromatin-modifiers-Albers baricitinib   176
6 4-20240823-ReN-chromatin-modifiers-Albers ruxolitinib   300

```



```{r}

rosmap_tdp43_classification <- syn("syn44277761") %>%
  read_csv()

rosmap_quant_clinical <- syn("syn44335073") %>%
  read_csv()

rosmap_quant_clinical_split <- rosmap_quant_clinical %>%
  mutate(
    across(-c(ID, brain_region, PMI, AOD, CDR, Braak), ~log10(.x + 1))
  ) %>%
  power_inner_join(
    distinct(rosmap_tdp43_classification, file, class_low, class_high),
    by = c("ID" = "file"),
    check = check_specs(
      duplicate_keys_left = "abort",
      duplicate_keys_right = "abort",
      unmatched_keys_left = "warn",
      unmatched_keys_right = "abort"
    )
  ) %>% {
    bind_rows(
      low_threshold = select(., -class_high) %>%
        rename(class = class_low),
      high_threshold = select(., -class_low) %>%
        rename(class = class_high),
      all = select(., -class_low, -class_high) %>%
        mutate(class = "all"),
      .id = "classification"
    )
  } %>%
  group_nest(brain_region, classification, class)
```


```{r}

dge_gmt <- map(
  c("syn20820056", "syn20820060"),
  ~syn(.x) %>%
    DRIAD::read_gmt()
) %>%
  enframe("experiment", "gene_sets") %>%
  mutate(
    gene_sets = map(gene_sets, ~enframe(.x, "drug", "genes"))
  ) %>%
  unnest(gene_sets)


drug_meta <- syn("syn11801537") %>%
  read_csv()

drugs_of_interest <- drug_meta %>%
  filter(
    name %in% c(
      "Ruxolitinib", "Baricitinib", "Tofacitinib", "Nilotinib", "Vorinostat", "NVP-TAE684"
    )
  )

dge_gmt_of_interest <- dge_gmt %>%
  inner_join(
    drugs_of_interest,
    by = c("drug" = "lincs_id")
  )

gmt_genes <- dge_gmt_of_interest$genes %>%
  reduce(union)
setdiff(gmt_genes, colnames(rosmap_quant_clinical))

gene_set_sizes <- map_int(dge_gmt_of_interest$genes, length) %>%
  unique()

```


Re-use prediction tasks created for chromatin modifier run

```{r}
# qsave(
#   prediction_tasks_pairs, file.path(data_dir, "prediction_tasks.qs")
# )
prediction_tasks_chromatin_mod <- syn("syn64765801") %>%
  qread() %>%
  mutate(
    task_path = file.path(data_dir, paste0(task_id, ".qs"))
  )

gene_set_sizes <- map_int(all_res_gene_sets$data, nrow) %>%
  unique()

gene_universe <- colnames(rosmap_quant_clinical) %>%
  setdiff(
    c("ID", "brain_region", "PMI", "AOD", "CDR",
      "Braak", "Barcode", "Label")
  )

setdiff(
  all_res_gene_sets$data %>%
    map("hgnc_symbol") %>%
    reduce(union),
  gene_universe
)

```

Adding prediction tasks for the `all` classification that weren't present
in the chromatin modifier run.

```{r}
prepare_task <- \(x, task) {
  task_map <- list(
    all_pooled = c("0", "0", "0", "1", "1", "2", "2"),
    all = as.character(0:6)
  )
  # browser()
  mutate(
    x,
    Label = task_map[[task]][Braak + 1] %>%
      fct_inseq(ordered = TRUE)
  )
}

set.seed(42)
prediction_tasks <- rosmap_quant_clinical_split %>%
  crossing(
    comparison = c("all", "all_pooled")
  ) %>%
  # Only use conditions that worked best in cross-validation
  filter(
    brain_region == "PCC",
    classification == "all"
  ) %>%
  mutate(
    task = map2(data, comparison, prepare_task)
  ) %>%
  select(-data) %>%
  mutate(
    task_id = paste("prediction_task", brain_region, classification, class, comparison, sep = "_"),
    task_path = file.path(data_dir, paste0(task_id, ".qs")),
    pairs = map(task, DRIAD::preparePairs)
  ) %>%
  bind_rows(
    prediction_tasks_chromatin_mod
  )

qsave(
  prediction_tasks, file.path(data_dir, "prediction_tasks.qs")
)
# prediction_tasks <- qread(file.path(data_dir, "prediction_tasks.qs"))

pwalk(
  prediction_tasks,
  function(task, pairs, task_path, ...) {
    # browser()
    x <- list(task = task, pairs = pairs)
    qsave(
      x,
      task_path
      # compress = "xz"
    )
  }
)

```



```{r}
compound_gene_sets <- all_res_gene_sets %>%
  mutate(
    data = map(
      data,
      \(x) drop_na(x, hgnc_symbol) %>%
        filter(hgnc_symbol %in% gene_universe)
    )
  ) %>%
  transmute(
    gene_set_size = map_int(data, nrow),
    genes = map(data, "hgnc_symbol"),
    gs_id
  )

```

```{r}

N_BACKGROUND_GENE_SETS <- 1000

set.seed(42)
background_gene_sets <- crossing(
  gene_set_size = gene_set_sizes,
  seq_id = seq_len(N_BACKGROUND_GENE_SETS)
) %>%
  mutate(
    genes = map(
      gene_set_size,
      \(x) sample(gene_universe, x, replace = FALSE)
    ),
    gs_id = paste0("background_", gene_set_size, "_", seq_id)
  )

qsave(
  background_gene_sets,
  file.path(data_dir, "background_gene_sets.qs")
)
background_gene_sets <- qread(file.path(data_dir, "background_gene_sets.qs"))

qsave(
  compound_gene_sets,
  file.path(data_dir, "compound_gene_sets.qs")
)
compound_gene_sets <- qread(file.path(data_dir, "compound_gene_sets.qs"))

combined_gene_sets <- bind_rows(
  compound = compound_gene_sets,
  background = background_gene_sets,
  .id = "gs_type"
)

# Enforce minimum gene set size of 10
# and use only high_threshold for now
combined_gene_sets_selected <- combined_gene_sets %>%
  filter(
    gene_set_size >= 10
  )

prediction_task_gene_set_pairs <- cross_join(
  prediction_tasks %>%
    select(-c(task, pairs)),
  combined_gene_sets_selected
) %>%
  # Only use all_pooled task
  filter(
    comparison == "all_pooled"
  )

qsave(
  prediction_task_gene_set_pairs,
  file.path(data_dir, "prediction_task_gene_set_pairs.qs")
)
prediction_task_gene_set_pairs <- qread(file.path(data_dir, "prediction_task_gene_set_pairs.qs"))

# Figuring out running time of each task / gene set size combination by
# running a few samples

set.seed(42)
prediction_task_gene_set_pairs_performance_selected <- prediction_task_gene_set_pairs %>%
  group_by(
    task_id, gene_set_size
  ) %>%
  slice_sample(n = 2) %>%
  ungroup() %>%
  mutate(
    gene_sets = map2(genes, gs_id, \(x, y) set_names(list(dummy = x), y))
  )

run_pred_job <- function(task_path, gene_sets, ...) {
  library(tidyverse)
  library(furrr)
  library(DRIAD)
  library(qs)
  library(here)

  plan(sequential)

  message("Reading task...", task_path)
  task <- qread(task_path)
  message("Evaluating gene sets...", length(gene_sets))
  res <- tryCatch({
    DRIAD::evalGeneSets(
      gene_sets,
      XY = task[["task"]],
      lP = task[["pairs"]],
      nBK = 0,
      method = "or"
    ) %>%
      dplyr::select(-Feats, -BK)
  },
  error = function(e) {
    warning(e)
    NULL
  }
  )
  message("Done...")
  res
}


library(batchtools)

reg <- makeRegistry(
  file.dir = here(paste0("registry_additional_jaks_run_time", gsub(" ", "_", Sys.time()))),
  seed = 1
)
# reg <- loadRegistry("reg  ")

batchMap(
  fun = run_pred_job,
  task_path = prediction_task_gene_set_pairs_performance_selected$task_path,
  gene_sets = prediction_task_gene_set_pairs_performance_selected$gene_sets,
  reg = reg
)

# run_bk_job(
#   task_id = prediction_tasks_gene_sets[1:5,][["id"]][[1]],
#   background_sets = prediction_tasks_gene_sets[1:5,][["background_sets"]][[1]],
#   background_task_id = prediction_tasks_gene_sets[1:5,][["background_task_id"]][[1]]
# )

job_table <- findJobs(reg = reg) %>%
  # Chunk jobs into a single array job
  mutate(chunk = 1)

submitJobs(
  job_table,
  resources = list(
    memory = "1gb",
    ncpus = 1L,
    partition = "short",
    walltime = 30*60,
    chunks.as.arrayjobs = TRUE
  )
)

running_times_raw <- getJobTable(findDone(reg = reg), reg = reg) %>%
  bind_cols(
    prediction_task_gene_set_pairs_performance_selected
  )

qsave(
  running_times_raw,
  file.path(data_dir, "running_times_raw.qs")
)

running_times <- running_times_raw %>%
  group_by(
    task_id, gene_set_size
  ) %>%
  summarize(
    est_running_time = mean(time.running),
    .groups = "drop"
  )

set.seed(42)
# Planning jobs so that each one should take ~1h
PLANNED_RUNNING_TIME <- 60*60
prediction_task_job_sets <- prediction_task_gene_set_pairs %>%
  power_inner_join(
    running_times,
    by = c("task_id", "gene_set_size"),
    check = check_specs(
      duplicate_keys_right = "warn",
      unmatched_keys_left = "warn",
      unmatched_keys_right = "warn"
    )
  ) %>%
  slice_sample(prop = 1) %>%
  group_by(task_id) %>%
  mutate(
    batch_id = floor(cumsum(unclass(est_running_time)) / PLANNED_RUNNING_TIME)
  ) %>%
  ungroup() %>%
  select(task_id, task_path, gs_id, batch_id, genes) %>%
  group_nest(task_id, task_path, batch_id) %>%
  mutate(
    gene_sets = map(data, \(x) set_names(x$genes, x$gs_id))
  )

qsave(
  prediction_task_job_sets, file.path(data_dir, "prediction_task_job_sets.qs")
)
# prediction_task_job_sets <- qread(file.path(data_dir, "prediction_task_job_sets.qs"))

reg <- makeRegistry(
  file.dir = here(paste0("registry_additional_jaks_", gsub(" ", "_", Sys.time()))),
  seed = 1
)
# reg <- loadRegistry("reg  ")

batchMap(
  fun = run_pred_job,
  task_path = prediction_task_job_sets$task_path,
  gene_sets = prediction_task_job_sets$gene_sets,
  reg = reg
)

job_table <- findJobs(reg = reg) %>%
  # Chunk jobs into a single array job
  mutate(chunk = 1)

submitJobs(
  job_table[findExpired()],
  resources = list(
    memory = "1gb",
    ncpus = 1L,
    partition = "short",
    walltime = 120*60,
    chunks.as.arrayjobs = TRUE
  ),
  reg = reg
)

# Check if errored jobs contain compound gene sets
prediction_task_job_sets %>%
  slice(
    # findErrors()$job.id
    -findDone(reg = reg)$job.id
  ) %>%
  select(-gene_sets) %>%
  unnest(data) %>%
  filter(str_detect(gs_id, "compound"))
# Nope!

all_res_raw <- reduceResultsDataTable(
  findDone(reg = reg), reg = reg
)

qsave(
  all_res_raw,
  file.path(data_dir, "all_res_raw.qs")
)
all_res_raw <- qread(file.path(data_dir, "all_res_raw.qs"))

all_res_joined <- all_res_raw %>%
  unnest(result) %>%
  rename(gs_id = Set) %>%
  power_inner_join(
    prediction_task_job_sets %>%
      transmute(
        job.id = seq_len(n()),
        task_id
      ),
    by = c("job.id"),
    check = check_specs(
      duplicate_keys_right = "warn",
      unmatched_keys_left = "warn",
      unmatched_keys_right = "warn"
    )
  ) %>%
  power_inner_join(
    prediction_task_gene_set_pairs %>%
      select(-c(genes, task_path)),
    by = c("task_id", "gs_id"),
    check = check_specs(
      duplicate_keys_left = "warn",
      duplicate_keys_right = "warn",
      unmatched_keys_left = "warn",
      unmatched_keys_right = "warn"
    )
  )

fwrite(
  select(all_res_joined, where(negate(is.list))),
  file.path(data_dir, "compound_and_background_res.csv.gz")
)



syn_dir <- synMkdir("syn45053114", "Additional JAKs")
synStoreMany(
  c(
    file.path(
      data_dir,
      c(
        "all_res_raw.qs",
        "compound_and_background_res.csv.gz",
        "background_gene_sets.qs",
        "prediction_tasks.qs",
        "prediction_task_gene_set_pairs.qs",
        "all_res_gene_sets.qs"
      )
    )
  ),
  syn_dir,
  forceVersion = FALSE
)



```

